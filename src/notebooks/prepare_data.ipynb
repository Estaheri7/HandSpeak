{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils import euclidean_distance, calculate_angle, is_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'..\\\\..\\\\dataset_landmarks'\n",
    "np_path = r'..\\\\..\\\\np_features'\n",
    "numeric_data_path = os.path.join(np_path, 'numeric_data.npy')\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "\n",
    "train_folder = os.path.join(dataset_path, TRAIN)\n",
    "test_folder = os.path.join(dataset_path, TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating directories to collection train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory Structure\n",
    "\n",
    "# For images\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "\n",
    "if not os.path.exists(test_folder):\n",
    "    os.makedirs(test_folder)\n",
    "\n",
    "# For numeric features\n",
    "if not os.path.exists(np_path):\n",
    "    os.makedirs(np_path)\n",
    "\n",
    "# Create special folders\n",
    "space_image_folder = 'space'\n",
    "backspace_image_folder = 'backspace'\n",
    "\n",
    "special_gestures = [space_image_folder, backspace_image_folder]\n",
    "\n",
    "for gesture in special_gestures:\n",
    "    # train\n",
    "    if not os.path.exists(train_folder + '\\\\' + gesture):\n",
    "        os.makedirs(train_folder + '\\\\' + gesture)\n",
    "    \n",
    "\n",
    "    # test\n",
    "    if not os.path.exists(test_folder + '\\\\' + gesture):\n",
    "        os.makedirs(test_folder + '\\\\' + gesture)\n",
    "\n",
    "\n",
    "# Create folders for each word A-Z\n",
    "\n",
    "for i in string.ascii_uppercase:\n",
    "    train_folder_i = os.path.join(train_folder, i)\n",
    "    if not os.path.exists(train_folder_i):\n",
    "        os.makedirs(train_folder_i)\n",
    "    \n",
    "    test_folder_i = os.path.join(test_folder, i)\n",
    "    if not os.path.exists(test_folder_i):\n",
    "        os.makedirs(test_folder_i)\n",
    "\n",
    "if not os.path.exists(numeric_data_path):\n",
    "    numeric_data = np.empty((0, 16))\n",
    "    np.save(numeric_data_path, numeric_data)\n",
    "else:\n",
    "    numeric_data = np.load(numeric_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below we will collect data using opencv and process the images before saving them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Grayscale Conversion`: Reduces complexity by focusing on brightness variations, discarding color information that is irrelevant for gesture recognition.\n",
    "\n",
    "`Gaussian Blur`: Softens the image, reducing high-frequency noise while preserving edges.\n",
    "\n",
    "`Thresholding`: Converts the image to a binary format (black and white), highlighting the hand's contour. This simplifies the image, making it easier for the model to learn the shape and structure of different signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive thresholding and binary inversion help separate the hand from the background, ensuring the model doesn't get distracted by irrelevant objects or patterns in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = TRAIN\n",
    "directory = os.path.join(dataset_path, mode) + '/'\n",
    "min_value = 70\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "interrupt = -1\n",
    "\n",
    "hand_detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "\n",
    "# Define hand landmark connections based on MediaPipe's hand model\n",
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),  # Thumb\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),  # Index Finger\n",
    "    (0, 9), (9, 10), (10, 11), (11, 12),  # Middle Finger\n",
    "    (0, 13), (13, 14), (14, 15), (15, 16),  # Ring Finger\n",
    "    (0, 17), (17, 18), (18, 19), (19, 20),  # Pinky Finger\n",
    "    (5, 9), (9, 13), (13, 17)  # Palm connections\n",
    "]\n",
    "\n",
    "# Close the video capture by pressing '`'\n",
    "# Change the mode between Train and Test with '/'\n",
    "while True:\n",
    "    _, frame = capture.read()\n",
    "\n",
    "    # Simulating mirror Image\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    hands, _ = hand_detector.findHands(frame, draw=False)\n",
    "\n",
    "    # Get count of existing images\n",
    "    count = {\n",
    "                'space': len(os.listdir(directory+\"/space\")),\n",
    "                'backspace': len(os.listdir(directory+\"/backspace\")),\n",
    "\n",
    "                'a': len(os.listdir(directory+\"/A\")),\n",
    "                'b': len(os.listdir(directory+\"/B\")),\n",
    "                'c': len(os.listdir(directory+\"/C\")),\n",
    "                'd': len(os.listdir(directory+\"/D\")),\n",
    "                'e': len(os.listdir(directory+\"/E\")),\n",
    "                'f': len(os.listdir(directory+\"/F\")),\n",
    "                'g': len(os.listdir(directory+\"/G\")),\n",
    "                'h': len(os.listdir(directory+\"/H\")),\n",
    "                'i': len(os.listdir(directory+\"/I\")),\n",
    "                'j': len(os.listdir(directory+\"/J\")),\n",
    "                'k': len(os.listdir(directory+\"/K\")),\n",
    "                'l': len(os.listdir(directory+\"/L\")),\n",
    "                'm': len(os.listdir(directory+\"/M\")),\n",
    "                'n': len(os.listdir(directory+\"/N\")),\n",
    "                'o': len(os.listdir(directory+\"/O\")),\n",
    "                'p': len(os.listdir(directory+\"/P\")),\n",
    "                'q': len(os.listdir(directory+\"/Q\")),\n",
    "                'r': len(os.listdir(directory+\"/R\")),\n",
    "                's': len(os.listdir(directory+\"/S\")),\n",
    "                't': len(os.listdir(directory+\"/T\")),\n",
    "                'u': len(os.listdir(directory+\"/U\")),\n",
    "                'v': len(os.listdir(directory+\"/V\")),\n",
    "                'w': len(os.listdir(directory+\"/W\")),\n",
    "                'x': len(os.listdir(directory+\"/X\")),\n",
    "                'y': len(os.listdir(directory+\"/Y\")),\n",
    "                'z': len(os.listdir(directory+\"/Z\")),\n",
    "    }\n",
    "\n",
    "    numeric_data = np.load(numeric_data_path)\n",
    "\n",
    "    # Display the count of each letter on the screen\n",
    "\n",
    "    x_text = int(0.8 * frame.shape[1])\n",
    "    x_mode = int(0.6 * frame.shape[1])\n",
    "    y_start = 20 \n",
    "    y_step = 13\n",
    "\n",
    "    for i, letter in enumerate(sorted(count.keys())):\n",
    "        y_pos = y_start + i * y_step  # Calculate y position dynamically\n",
    "        text = f\"{letter.upper()} : {count[letter]}\"\n",
    "        cv2.putText(frame, text, (x_text, y_pos), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1)\n",
    "\n",
    "    # Display mode of the folder (train / test) \n",
    "    cv2.putText(frame, f'Mode: {mode}', (x_mode, y_start), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1)\n",
    "\n",
    "    # Coordinates of the ROI\n",
    "    \n",
    "    x1 = 10\n",
    "    y1 = 10\n",
    "    x2 = int(0.5 * frame.shape[1])\n",
    "    y2 = int(0.5 * frame.shape[1])\n",
    "\n",
    "    # Draw the ROI box\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255, 0, 0), 1)\n",
    "\n",
    "    # Extract the ROI\n",
    "    region_of_interest = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    # Image Processing\n",
    "    # Grayscale Conversion\n",
    "    gray = cv2.cvtColor(region_of_interest, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Gaussian Blur\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 2)\n",
    "    \n",
    "    # Thresholding \n",
    "    th3 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    ret, processed_image = cv2.threshold(th3, min_value, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Resizing and Displaying proccessed image\n",
    "    processed_image = cv2.resize(processed_image, (300,300))\n",
    "    landmarks_frame = np.ones_like(region_of_interest) * 255\n",
    "    \n",
    "    numeric_list = []\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            landmarks = hand[\"lmList\"]  # List of 21 hand landmark points\n",
    "            # Draw lines between hand landmarks\n",
    "            for connection in HAND_CONNECTIONS:\n",
    "                pt1 = tuple(landmarks[connection[0]][:2])  # First point (x, y)\n",
    "                pt2 = tuple(landmarks[connection[1]][:2])  # Second point (x, y)\n",
    "                cv2.line(landmarks_frame, pt1, pt2, (0, 255, 0), 2)  # Green lines\n",
    "\n",
    "            # Draw circles on each landmark\n",
    "            for lm in landmarks:\n",
    "                cv2.circle(landmarks_frame, tuple(lm[:2]), 5, (0, 0, 255), -1)\n",
    "            \n",
    "            # Distance between the wist and fingertips\n",
    "            wist_thumb = euclidean_distance(landmarks[0], landmarks[4])\n",
    "            wist_index = euclidean_distance(landmarks[0], landmarks[8])\n",
    "            wist_middle = euclidean_distance(landmarks[0], landmarks[12])\n",
    "            wist_ping = euclidean_distance(landmarks[0], landmarks[16])\n",
    "            wist_pinky = euclidean_distance(landmarks[0], landmarks[20])\n",
    "\n",
    "            # Distance between special fingertips\n",
    "            thumb_index = euclidean_distance(landmarks[4], landmarks[8])\n",
    "            thumb_pinky = euclidean_distance(landmarks[4], landmarks[20])\n",
    "            thumb_middle = euclidean_distance(landmarks[4], landmarks[12])\n",
    "            index_middle = euclidean_distance(landmarks[8], landmarks[12])\n",
    "\n",
    "            # Other numerical features\n",
    "            index_middle_dip = euclidean_distance(landmarks[7], landmarks[11])\n",
    "            index_middle_z = euclidean_distance(landmarks[8][2], landmarks[12][2])\n",
    "            thumb_ping_angle = calculate_angle(landmarks[4], landmarks[0], landmarks[16])\n",
    "            thumb_index_angle = calculate_angle(landmarks[4], landmarks[0], landmarks[8])\n",
    "            index_middle_angle = calculate_angle(landmarks[8], landmarks[0], landmarks[12])\n",
    "\n",
    "            thumb_index_above = int(is_above(landmarks[4][1], landmarks[8][1]))\n",
    "            \n",
    "            numeric_list.extend([wist_thumb, wist_index, wist_middle, wist_ping, wist_pinky,\n",
    "                                 thumb_index, thumb_middle, thumb_pinky, index_middle,\n",
    "                                 index_middle_dip, index_middle_z, thumb_ping_angle, thumb_index_angle,\n",
    "                                 index_middle_angle, thumb_index_above])\n",
    "            \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow('landmarks', landmarks_frame)\n",
    "    cv2.imshow('Processed Image', processed_image)\n",
    "\n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == ord('`'): \n",
    "        # escape key\n",
    "        break\n",
    "    if interrupt & 0xFF == ord('/'):\n",
    "        # change mode\n",
    "        mode = TRAIN if mode == TEST else TEST\n",
    "        directory = os.path.join(dataset_path, mode) + '/'\n",
    "        \n",
    "    keys = {\n",
    "    'space': 32,\n",
    "    'backspace': 8,\n",
    "    **{chr(i): ord(chr(i)) for i in range(ord('a'), ord('z') + 1)}\n",
    "    }\n",
    "\n",
    "    for key, ascii_value in keys.items():\n",
    "        if interrupt & 0xFF == ascii_value:\n",
    "            cv2.imwrite(f\"{directory}{key}/{count[key]}.jpg\", landmarks_frame)\n",
    "            if mode == TRAIN:\n",
    "                numeric_list.append(ascii_value)\n",
    "                np.save(numeric_data_path, np.vstack([numeric_data, np.array(numeric_list).reshape(1, 16)]))  \n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
