{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils import euclidean_distance, calculate_angle, is_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'..\\\\..\\\\dataset_landmarks'\n",
    "np_path = r'..\\\\..\\\\np_features'\n",
    "numeric_data_path = os.path.join(np_path, 'numeric_data.npy')\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "\n",
    "train_folder = os.path.join(dataset_path, TRAIN)\n",
    "test_folder = os.path.join(dataset_path, TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating directories to collection train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory Structure\n",
    "\n",
    "# For images\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "\n",
    "if not os.path.exists(test_folder):\n",
    "    os.makedirs(test_folder)\n",
    "\n",
    "# For numeric features\n",
    "if not os.path.exists(np_path):\n",
    "    os.makedirs(np_path)\n",
    "\n",
    "# Create special folders\n",
    "space_image_folder = 'space'\n",
    "\n",
    "special_gestures = [space_image_folder]\n",
    "\n",
    "for gesture in special_gestures:\n",
    "    # train\n",
    "    if not os.path.exists(train_folder + '\\\\' + gesture):\n",
    "        os.makedirs(train_folder + '\\\\' + gesture)\n",
    "    \n",
    "\n",
    "    # test\n",
    "    if not os.path.exists(test_folder + '\\\\' + gesture):\n",
    "        os.makedirs(test_folder + '\\\\' + gesture)\n",
    "\n",
    "\n",
    "# Create folders for each word A-Z\n",
    "\n",
    "for i in string.ascii_uppercase:\n",
    "    train_folder_i = os.path.join(train_folder, i)\n",
    "    if not os.path.exists(train_folder_i):\n",
    "        os.makedirs(train_folder_i)\n",
    "    \n",
    "    test_folder_i = os.path.join(test_folder, i)\n",
    "    if not os.path.exists(test_folder_i):\n",
    "        os.makedirs(test_folder_i)\n",
    "\n",
    "if not os.path.exists(numeric_data_path):\n",
    "    numeric_data = np.empty((0, 16))\n",
    "    np.save(numeric_data_path, numeric_data)\n",
    "else:\n",
    "    numeric_data = np.load(numeric_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below we will collect data using opencv and process the images before saving them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using landmarks\n",
    "\n",
    "This method will help us to predict with higher accuracy in different situations (light, background, or even hand-size)\n",
    "\n",
    "For this first we collect data from hand gestures using two hand detectors\n",
    "1. `hand_detector` (First Detector):\n",
    "   - Detects the hand in the full frame.\n",
    "   - Provides the bounding box (`bbox`) of the detected hand.\n",
    "   - Used to extract and crop the hand from the original frame.\n",
    "2. `cropped_hand_detector (Second Detector):\n",
    "   - Runs on the cropped hand region extracted using the first detector.\n",
    "   - Re-detects the hand within the smaller cropped area.\n",
    "   - Provides more precise landmark positions within the cropped image.\n",
    "   - Used to draw landmarks and connections on a static 300x300 frame.\n",
    "\n",
    "### Advantages of this method:\n",
    "1. Better Accuracy in Landmark Detection\n",
    "2. Ensures Hand is Properly Centered in Static Image\n",
    "3. Avoids Scaling Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landmarks features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined 15 different features for landmarks\n",
    "\n",
    "- Distance between the wrist and fingertips:\n",
    "    - `wist_thumb`: Distance between wrist and thumb tip.\n",
    "    - `wist_index`: Distance between wrist and index finger tip.\n",
    "    - `wist_middle`: Distance between wrist and middle finger tip.\n",
    "    - `wist_ping`: Distance between wrist and ring finger tip.\n",
    "    - `wist_pinky`: Distance between wrist and pinky finger tip.\n",
    "\n",
    "- Distance between specific fingertips:\n",
    "    - `thumb_index`: Distance between thumb tip and index finger tip.\n",
    "    - `thumb_pinky`: Distance between thumb tip and pinky finger tip.\n",
    "    - `thumb_middle`: Distance between thumb tip and middle finger tip.\n",
    "    - `index_middle`: Distance between index finger tip and middle finger tip.\n",
    "\n",
    "- Other numerical features:\n",
    "    - `index_middle_dip`: Distance between the DIP joints of index and middle fingers.\n",
    "    - `index_middle_z`: Z-axis distance between index and middle finger tips.\n",
    "    - `thumb_ping_angle`: Angle formed by thumb tip, wrist, and ring finger tip.\n",
    "    - `thumb_index_angle`: Angle formed by thumb tip, wrist, and index finger tip.\n",
    "    - `index_middle_angle`: Angle formed by index finger tip, wrist, and middle finger tip.\n",
    "    - `thumb_index_above`: Binary feature indicating if the index finger tip is above the thumb tip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = TRAIN\n",
    "directory = os.path.join(dataset_path, mode) + '/'\n",
    "min_value = 70\n",
    "\n",
    "PAD = 20\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "interrupt = -1\n",
    "\n",
    "hand_detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "cropped_hand_detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "\n",
    "# Define hand landmark connections based on MediaPipe's hand model\n",
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),  # Thumb\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),  # Index Finger\n",
    "    (0, 9), (9, 10), (10, 11), (11, 12),  # Middle Finger\n",
    "    (0, 13), (13, 14), (14, 15), (15, 16),  # Ring Finger\n",
    "    (0, 17), (17, 18), (18, 19), (19, 20),  # Pinky Finger\n",
    "    (5, 9), (9, 13), (13, 17)  # Palm connections\n",
    "]\n",
    "\n",
    "# Close the video capture by pressing '`'\n",
    "# Change the mode between Train and Test with '/'\n",
    "while True:\n",
    "    _, frame = capture.read()\n",
    "\n",
    "    # Simulating mirror Image\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "    hands, _ = hand_detector.findHands(frame, draw=False)\n",
    "\n",
    "    # Get count of existing images\n",
    "    count = {\n",
    "                'space': len(os.listdir(directory+\"/space\")),\n",
    "\n",
    "                'a': len(os.listdir(directory+\"/A\")),\n",
    "                'b': len(os.listdir(directory+\"/B\")),\n",
    "                'c': len(os.listdir(directory+\"/C\")),\n",
    "                'd': len(os.listdir(directory+\"/D\")),\n",
    "                'e': len(os.listdir(directory+\"/E\")),\n",
    "                'f': len(os.listdir(directory+\"/F\")),\n",
    "                'g': len(os.listdir(directory+\"/G\")),\n",
    "                'h': len(os.listdir(directory+\"/H\")),\n",
    "                'i': len(os.listdir(directory+\"/I\")),\n",
    "                'j': len(os.listdir(directory+\"/J\")),\n",
    "                'k': len(os.listdir(directory+\"/K\")),\n",
    "                'l': len(os.listdir(directory+\"/L\")),\n",
    "                'm': len(os.listdir(directory+\"/M\")),\n",
    "                'n': len(os.listdir(directory+\"/N\")),\n",
    "                'o': len(os.listdir(directory+\"/O\")),\n",
    "                'p': len(os.listdir(directory+\"/P\")),\n",
    "                'q': len(os.listdir(directory+\"/Q\")),\n",
    "                'r': len(os.listdir(directory+\"/R\")),\n",
    "                's': len(os.listdir(directory+\"/S\")),\n",
    "                't': len(os.listdir(directory+\"/T\")),\n",
    "                'u': len(os.listdir(directory+\"/U\")),\n",
    "                'v': len(os.listdir(directory+\"/V\")),\n",
    "                'w': len(os.listdir(directory+\"/W\")),\n",
    "                'x': len(os.listdir(directory+\"/X\")),\n",
    "                'y': len(os.listdir(directory+\"/Y\")),\n",
    "                'z': len(os.listdir(directory+\"/Z\")),\n",
    "    }\n",
    "\n",
    "    numeric_data = np.load(numeric_data_path)\n",
    "\n",
    "    # Display the count of each letter on the screen\n",
    "\n",
    "    x_text = int(0.8 * frame.shape[1])\n",
    "    x_mode = int(0.6 * frame.shape[1])\n",
    "    y_start = 20 \n",
    "    y_step = 13\n",
    "\n",
    "    for i, letter in enumerate(sorted(count.keys())):\n",
    "        y_pos = y_start + i * y_step  # Calculate y position dynamically\n",
    "        text = f\"{letter.upper()} : {count[letter]}\"\n",
    "        cv2.putText(frame, text, (x_text, y_pos), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1)\n",
    "\n",
    "    # Display mode of the folder (train / test) \n",
    "    cv2.putText(frame, f'Mode: {mode}', (x_mode, y_start), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 255), 1)\n",
    "\n",
    "    # Coordinates of the ROI\n",
    "    \n",
    "    x1 = 10\n",
    "    y1 = 10\n",
    "    x2 = int(0.5 * frame.shape[1])\n",
    "    y2 = int(0.5 * frame.shape[1])\n",
    "\n",
    "    # clean white frame\n",
    "    landmarks_frame = np.ones((350, 350, 3), np.uint8) * 255\n",
    "\n",
    "    numeric_list = []\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            x, y, w, h = hand['bbox']\n",
    "            x1 = max(0, x - PAD)\n",
    "            y1 = max(0, y - PAD)\n",
    "            x2 = min(frame.shape[1], x + w + PAD)\n",
    "            y2 = min(frame.shape[0], y + h + PAD)\n",
    "\n",
    "            # Crop the hand region\n",
    "            image = frame[y1:y2, x1:x2].copy()\n",
    "\n",
    "            # Re-detect the hand using the hand region \n",
    "            crop_hand, _ = cropped_hand_detector.findHands(image, draw=True)\n",
    "            if crop_hand:\n",
    "                hand = crop_hand[0]\n",
    "                landmarks = hand['lmList']\n",
    "                scale_x = ((350-w)//2)-10\n",
    "                scale_y = ((350-h)//2)-10\n",
    "                \n",
    "                # Draw lines between hand landmarks            \n",
    "                for connection in HAND_CONNECTIONS:\n",
    "                    pt1 = (landmarks[connection[0]][0]+scale_x, landmarks[connection[0]][1]+scale_y)  # First point (x, y)\n",
    "                    pt2 = (landmarks[connection[1]][0]+scale_x, landmarks[connection[1]][1]+scale_y)  # Second point (x, y)\n",
    "                    cv2.line(landmarks_frame, pt1, pt2, (0, 255, 0), 2)  # Green lines\n",
    "\n",
    "                # Draw circles on each landmark\n",
    "                for lm in landmarks:\n",
    "                    point_x = lm[0] + scale_x\n",
    "                    point_y = lm[1] + scale_y\n",
    "                    cv2.circle(landmarks_frame, (point_x, point_y), 5, (0, 0, 255), -1)\n",
    "                \n",
    "                # Distance between the wist and fingertips\n",
    "                wist_thumb = euclidean_distance(landmarks[0], landmarks[4])\n",
    "                wist_index = euclidean_distance(landmarks[0], landmarks[8])\n",
    "                wist_middle = euclidean_distance(landmarks[0], landmarks[12])\n",
    "                wist_ping = euclidean_distance(landmarks[0], landmarks[16])\n",
    "                wist_pinky = euclidean_distance(landmarks[0], landmarks[20])\n",
    "\n",
    "                # Distance between special fingertips\n",
    "                thumb_index = euclidean_distance(landmarks[4], landmarks[8])\n",
    "                thumb_pinky = euclidean_distance(landmarks[4], landmarks[20])\n",
    "                thumb_middle = euclidean_distance(landmarks[4], landmarks[12])\n",
    "                index_middle = euclidean_distance(landmarks[8], landmarks[12])\n",
    "\n",
    "                # Other numerical features\n",
    "                index_middle_dip = euclidean_distance(landmarks[7], landmarks[11])\n",
    "                index_middle_z = euclidean_distance(landmarks[8][2], landmarks[12][2])\n",
    "                thumb_ping_angle = calculate_angle(landmarks[4], landmarks[0], landmarks[16])\n",
    "                thumb_index_angle = calculate_angle(landmarks[4], landmarks[0], landmarks[8])\n",
    "                index_middle_angle = calculate_angle(landmarks[8], landmarks[0], landmarks[12])\n",
    "\n",
    "                thumb_index_above = int(is_above(landmarks[4][1], landmarks[8][1]))\n",
    "                \n",
    "                numeric_list.extend([wist_thumb, wist_index, wist_middle, wist_ping, wist_pinky,\n",
    "                                    thumb_index, thumb_middle, thumb_pinky, index_middle,\n",
    "                                    index_middle_dip, index_middle_z, thumb_ping_angle, thumb_index_angle,\n",
    "                                    index_middle_angle, thumb_index_above])\n",
    "            \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow('landmarks_frame', landmarks_frame)\n",
    "\n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == ord('`'): \n",
    "        # escape key\n",
    "        break\n",
    "    if interrupt & 0xFF == ord('/'):\n",
    "        # change mode\n",
    "        mode = TRAIN if mode == TEST else TEST\n",
    "        directory = os.path.join(dataset_path, mode) + '/'\n",
    "        \n",
    "    keys = {\n",
    "    'space': 32,\n",
    "    **{chr(i): ord(chr(i)) for i in range(ord('a'), ord('z') + 1)}\n",
    "    }\n",
    "\n",
    "    for key, ascii_value in keys.items():\n",
    "        if interrupt & 0xFF == ascii_value:\n",
    "            cv2.imwrite(f\"{directory}{key}/{count[key]}.jpg\", landmarks_frame)\n",
    "            if mode == TRAIN:\n",
    "                numeric_list.append(ascii_value)\n",
    "                np.save(numeric_data_path, np.vstack([numeric_data, np.array(numeric_list).reshape(1, 16)]))  \n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
